{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "private_outputs": true,
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "MkN0PbfMx4q_"
      },
      "outputs": [],
      "source": [
        "# 불피요한 warnings 이 길게 출력되는 막기 위한 코드이다.\n",
        "import warnings\n",
        "warnings.filterwarnings(\"ignore\")"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# 데이터 분석을 위한 pandas, 수치계산을 위한 numpy, 시각화를 위한 seaborn, matplotlib 을 불러온다.\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "import seaborn as sns\n",
        "import matplotlib.pyplot as plt"
      ],
      "metadata": {
        "id": "chHXd0GTzBqH"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install Koreanize-matplotlib"
      ],
      "metadata": {
        "id": "xVX-0x5PzBmG",
        "collapsed": true
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import koreanize_matplotlib\n",
        "\n",
        "# 그래프에 retina display 적용\n",
        "%config InlineBackend.figure_format = 'retina'\n",
        "\n",
        "pd.Series([1, 3, 5, -7, 9]).plot(title=\"한글\", figsize=(6, 1))"
      ],
      "metadata": {
        "id": "4uFdiwLczBii"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#corpus: 말뭉치 >> CountVectorizer()\n",
        "# DTM(Document-Term Matrix) 문서단어행렬 (빈도)\n",
        "# 5*3   (3*5)   5*5 lda >>> 가중치\n",
        "#dtm >> tf-df(Term-frequency-Inverse Document Frequency)\n",
        "#단어가 너무 많이 등장하면 의미가 없음 예: 은,는..)\n",
        "\n",
        "#vector화: 숫자로 변경\n",
        "#embedding(희소행렬 대부분이 0인 행렬)>> 밀집 행렬(dense)\n",
        "\n",
        "#통계와 머신러닝의 차이? 통계:조건부확률/빈도수/ VS 머신러닝: 일반화(기존 데이터 훈련->새로운 데이터 예측)"
      ],
      "metadata": {
        "id": "D6Hh22YezBd9"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "corpus = [\"코로나 거리두기와 코로나 상생지원금 문의입니다.\",\n",
        "          \"지하철 운행시간과 지하철 요금 문의입니다.\",\n",
        "          \"지하철 승강장 문의입니다.\",\n",
        "          \"택시 승강장 문의입니다.\"]\n",
        "corpus"
      ],
      "metadata": {
        "id": "iva_rJa9zBZ8"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# fit, transform, fit_transfrom의 차이점\n",
        "\n",
        "'''\n",
        "# fit, transform, fit_transfrom의 차이점\n",
        "* fit(): 원시 문서에 있는 모든 토큰의 어휘 사전을 배운다.\n",
        "* transform(): 문서를 문서 용어 매트릭스로 변환합니다. transform 이후엔 매트릭스로 변환되어 숫자형태로 변경된다.\n",
        "* fit_transform(): 어휘 사전을 배우고 문서 용어 매트릭스를 반환한다. fit 다음에 변환이 오는 것과 동일하지만 더 효율적으로 구현된다.\n",
        "'''"
      ],
      "metadata": {
        "id": "54AgRE0V3LzR"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#단어의 빈도를 Count하여 Vector로 생성\n",
        "from sklearn.feature_extraction.text import CountVectorizer\n",
        "\n",
        "cvect=CountVectorizer()\n",
        "cvect.fit(corpus)\n",
        "dtm=cvect.transform(corpus) #문서단어 행렬 생성\n",
        "dtm"
      ],
      "metadata": {
        "id": "otT_t1kJzBWN"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "dtm.toarray() #각 단어의 빈도수를 기록(문장 순서대로 X/ 부여 인덱스 확인 필요 )"
      ],
      "metadata": {
        "id": "a0qIrJuazBTT"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "cvect.vocabulary_  ## 각 단어의 인덱스가 어떻게 부여되었는지"
      ],
      "metadata": {
        "id": "RSTeWouzz71U"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# vectorizer.get_feature_names_out() : 벡터 형태로 반환\n",
        "vocab=cvect.get_feature_names_out()\n",
        "vocab"
      ],
      "metadata": {
        "id": "Peevwf_nz7u7"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#dtm\n",
        "df_dtm=pd.DataFrame(dtm.toarray(),columns=vocab)\n",
        "df_dtm"
      ],
      "metadata": {
        "id": "teL9yUJxz7mu"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#데이터프레임으로 변환\n",
        "df_dtm.sum().to_frame()"
      ],
      "metadata": {
        "id": "5rhnzAfl2_pQ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#가로, 세로 변환\n",
        "df_dtm.sum().to_frame().T"
      ],
      "metadata": {
        "id": "jK4zN9SI2_k1"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "'''\n",
        "# N-grams\n",
        "\n",
        "* 토큰을 몇 개 사용할 것인지를 구분합니다. 지정한 n개의 숫자 만큼의 토큰을 묶어서 사용한다.\n",
        "* 예를 들어 (1, 1) 이라면 1개의 토큰을 (2, 3)이라면 2~3개의 토큰을 사용한다.\n",
        "* analyzer 설정에 따라 단어단위, 캐릭터 단위에 따라 사용할 수 있다.\n",
        "\n",
        "* 기본값 = (1, 1)\n",
        "* ngram_range(min_n, max_n)\n",
        "* min_n <= n <= max_n\n",
        "```\n",
        "(1, 1) 은 1 <= n <= 1\n",
        "(1, 2) 은 1 <= n <= 2\n",
        "(2, 2) 은 2 <= n <= 2\n",
        "'''"
      ],
      "metadata": {
        "id": "5qsBqy-Y50nO"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "cvect=CountVectorizer(ngram_range=(1,2))\n",
        "#transform(): 문서를 문서 용어 매트릭스로 변환되어 숫자형태로 변경된다.\n",
        "#문서단어 행렬 생성\n",
        "dtm=cvect.fit_transform(corpus)\n",
        "dtm.toarray()"
      ],
      "metadata": {
        "id": "_xnn_EVl50fq"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "cvect.vocabulary_"
      ],
      "metadata": {
        "id": "w6EbmBAtfsHR"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "vocab=cvect.get_feature_names_out()\n",
        "df_dtm=pd.DataFrame(dtm.toarray(),columns=vocab)\n",
        "df_dtm"
      ],
      "metadata": {
        "id": "oKAWHt0i50ZN"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df_dtm.sum().to_frame().T"
      ],
      "metadata": {
        "id": "fwlYz4RP50Sy"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "'''\n",
        "# min_df\n",
        "\n",
        "* 기본값=1\n",
        "* min_df는 문서 빈도(문서의 %에 있음)가 지정된 임계값보다 엄격하게 낮은 용어를 무시한다.\n",
        "* 예를 들어, min_df=0.66은 용어가 어휘의 일부로 간주되려면 문서의 66%에 나타나야 한다.\n",
        "* 때때로 min_df가 어휘 크기를 제한하는 데 사용된다.\n",
        "* 예를들어 min_df를 0.1, 0.2로 설정한다면 10%, 20%에 나타나는 용어만 학습한다.\n",
        "'''"
      ],
      "metadata": {
        "id": "7PiBkwye50Mc"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "'''\n",
        "# max_df\n",
        "\n",
        "* 기본값=**1**\n",
        "* max_df=int : 빈도수를 의미한다.\n",
        "* max_df=float : 비율을 의미한다.\n",
        "* 어휘를 작성할 때 주어진 임계값보다 문서 빈도가 엄격히 높은 용어는 무시한다.\n",
        "* 빈번하게 등장하는 불용어 등을 제거하기에 편리하다.\n",
        "* 예를 들어 코로나 관련 기사를 분석하면 90%에 '코로나'라는 용어가 등장할 수 있는데, 이 경우 max_df=0.89 로 비율을 설정하여 너무 빈번하게 등장하는 단어를 제외할 수 있다.\n",
        "'''"
      ],
      "metadata": {
        "id": "d6R6V0R682f5"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#max_features:갯수만큼의 단어만 추출\n",
        "cvect=CountVectorizer(ngram_range=(1,3),min_df=0.2,max_df=5,max_features=10)\n",
        "dtm=cvect.fit_transform(corpus)\n",
        "dtm.toarray()"
      ],
      "metadata": {
        "id": "eQwqVM-W82aE"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "vocab=cvect.get_feature_names_out()\n",
        "df_dtm=pd.DataFrame(dtm.toarray(),columns=vocab)\n",
        "df_dtm"
      ],
      "metadata": {
        "id": "ilXBw7fj82U5"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# 불용어 stop_words\n",
        "stop_words=['코로나','문의입니다']\n",
        "\n",
        "#max_features:갯수만큼의 단어만 추출\n",
        "cvect=CountVectorizer(ngram_range=(1,3),min_df=0.2,max_df=5,max_features=10,stop_words=stop_words)\n",
        "dtm=cvect.fit_transform(corpus)\n",
        "dtm.toarray()"
      ],
      "metadata": {
        "id": "Vn3CzNW_82Ol"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "vocab=cvect.get_feature_names_out()\n",
        "df_dtm=pd.DataFrame(dtm.toarray(),columns=vocab)\n",
        "df_dtm"
      ],
      "metadata": {
        "id": "kNn3jemG82Ls"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#analyzer: 학습단위\n",
        "#기본값: word\n",
        "#cha,char_wb: 글자\n",
        "\n",
        "#불용어\n",
        "stop_words=['코로나','문의입니다']\n",
        "\n",
        "#max_features:갯수만큼의 단어만 추출\n",
        "cvect=CountVectorizer(analyzer='char',ngram_range=(1,3),min_df=0.2,max_df=5,max_features=10,stop_words=stop_words)\n",
        "dtm=cvect.fit_transform(corpus)\n",
        "dtm.toarray()"
      ],
      "metadata": {
        "id": "nLjtTq6R9BG8"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "vocab=cvect.get_feature_names_out()\n",
        "df_dtm=pd.DataFrame(dtm.toarray(),columns=vocab)\n",
        "df_dtm"
      ],
      "metadata": {
        "id": "4Jx5zYA-9BCW"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "###TF-IDF\n",
        "- 각 단어들마다 중요한 정도를 가중치로 주는 방법\n",
        "- 작을수록 중요한 단어\n",
        "\n",
        "- tf: 특정 문서 d에서의 특정 단어 t의 등장 횟수\n",
        "- df: 특정 단어 t가 등장한 문서의 수\n",
        "- idf: df의 역수 -> log(n/1+df(t))\n",
        "    - log 사용 이유? 스케일 조정, 특정 단어의 가중치 격차 조정\n",
        "    - +1 ? 분모 0이 되는 것을 방지\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "v0Q4vosMrlWr"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#tf-idf\n",
        "from sklearn.feature_extraction.text import TfidfVectorizer\n",
        "\n",
        "tfidfvect=TfidfVectorizer()\n",
        "tfidfvect.fit(corpus)\n",
        "\n",
        "dtm=tfidfvect.transform(corpus)\n",
        "dtm\n",
        "dtm.toarray()"
      ],
      "metadata": {
        "id": "5Dq7guBj9A-W"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "vocab=tfidfvect.get_feature_names_out()\n",
        "df_dtm=pd.DataFrame(dtm.toarray(),columns=vocab)\n",
        "df_dtm"
      ],
      "metadata": {
        "id": "lBBSJcBp9A65"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print('단어 수:',len(vocab))"
      ],
      "metadata": {
        "id": "zsyyz27LEWD1"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "display(df_dtm.style.background_gradient())"
      ],
      "metadata": {
        "id": "SOUibmKXEV8q"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "tfidfvect.idf_\n",
        "#하나의 문서에만 나타나는 토큰은 idf 가중치가 높다\n",
        "#df: 특정 단어가 나타나는 문서의 수로 크면 가중치 낮음"
      ],
      "metadata": {
        "id": "QeaBLrL3EV0O"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "idf=tfidfvect.idf_"
      ],
      "metadata": {
        "id": "OkAwL27nG8P2"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "vocab=tfidfvect.get_feature_names_out()\n",
        "vocab"
      ],
      "metadata": {
        "id": "PVEJr9afEVqo"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "zip(vocab,idf)"
      ],
      "metadata": {
        "id": "rdqo-bgWEVnK"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "idf_dict=dict(zip(vocab,idf))\n",
        "idf_dict"
      ],
      "metadata": {
        "id": "z9Gfn5-cGHp-"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "pd.Series(idf_dict).plot.barh()"
      ],
      "metadata": {
        "id": "Wl0Jn8ZDGHgh"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#템플릿\n",
        "\n",
        "tfidfvect=TfidfVectorizer(analyzer='word',ngram_range=(1,2),max_df=1.0,min_df=1)\n",
        "dtm=tfidfvect.fit_transform(corpus)\n",
        "vocab=tfidfvect.get_feature_names_out()\n",
        "df_dtm=pd.DataFrame(dtm.toarray(),columns=vocab)\n",
        "print('단어수:',len(vocab))\n",
        "print(vocab)\n",
        "display(df_dtm.style.background_gradient())"
      ],
      "metadata": {
        "id": "NNaTTTepGgyi"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "gTXKXu98HvgD"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}